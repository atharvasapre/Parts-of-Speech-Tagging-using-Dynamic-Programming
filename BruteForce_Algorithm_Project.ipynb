{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BruteForce Algorithm - Project",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tRV988KgD6SM"
      },
      "outputs": [],
      "source": [
        "# Importing packages and loading in the data set \n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import string\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class bruteforce:\n",
        "\n",
        "\n",
        "  def __init__(self,training,voc, test_corpus, test):\n",
        "\n",
        "    # Punctuation characters\n",
        "    self.punct = set(string.punctuation)\n",
        "\n",
        "    # Morphology rules used to assign unknown word tokens\n",
        "    self.noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
        "    self.verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
        "    self.adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
        "    self.adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
        "\n",
        "\n",
        "    with open(training, 'r') as f:\n",
        "      training_corpus = f.readlines()\n",
        "\n",
        "    with open(voc, 'r') as f:\n",
        "      voc_l = f.read().split('\\n')\n",
        "\n",
        "    # vocab: dictionary that has the index of the corresponding words\n",
        "    self.vocab = {} \n",
        "\n",
        "    # Get the index of the corresponding words. \n",
        "    for i, word in enumerate(sorted(voc_l)): \n",
        "        self.vocab[word] = i   \n",
        "\n",
        "    #Reading the test corpus\n",
        "    with open(test_corpus, 'r') as f:\n",
        "      self.y = f.readlines()\n",
        "\n",
        "\n",
        "\n",
        "    #corpus without tags, preprocessed\n",
        "    self._, self.prep = self.preprocess(self.vocab, test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    self.cnt = 0\n",
        "    for k,v in self.vocab.items():\n",
        "        self.cnt += 1\n",
        "        if self.cnt > 20:\n",
        "            break\n",
        "\n",
        "    #create dictionaries\n",
        "    self.emission_counts, self.transition_counts, self.tag_counts = self.create_dictionaries(training_corpus, self.vocab)\n",
        "\n",
        "    # get all the POS states\n",
        "    self.states = sorted(self.tag_counts.keys())\n",
        "\n",
        "\n",
        "    accuracy_predict_pos = self.predict_pos(self.prep, self.y, self.emission_counts, self.vocab, self.states)\n",
        "    print(f\"Accuracy of prediction using the brute force method is {accuracy_predict_pos*100:4f} %\")\n",
        "\n",
        "\n",
        "\n",
        "  def get_word_tag(self,line, vocab): \n",
        "    #helper function\n",
        "      if not line.split():\n",
        "          word = \"--n--\"\n",
        "          tag = \"--s--\"\n",
        "          return word, tag\n",
        "      else:\n",
        "          word, tag = line.split()\n",
        "          if word not in vocab: \n",
        "              word = self.assign_unk(word)\n",
        "          return word, tag\n",
        "      return None \n",
        "\n",
        "\n",
        "  def preprocess(self, vocab, data_fp):\n",
        "      '''\n",
        "      Input: \n",
        "          data_fp: file pointer to test data\n",
        "          vocab: a dictionary where keys are words in vocabulary and value is an index\n",
        "          \n",
        "      Output: \n",
        "          orig: original data with words and the assigned POS tags\n",
        "          prep: Data without the POS tags for testing\n",
        "      '''\n",
        "      orig = []\n",
        "      prep = []\n",
        "\n",
        "      with open(data_fp, \"r\") as data_file:\n",
        "\n",
        "          for cnt, word in enumerate(data_file):\n",
        "              if not word.split():\n",
        "                  orig.append(word.strip())\n",
        "                  word = \"--n--\"\n",
        "                  prep.append(word)\n",
        "                  continue\n",
        "              elif word.strip() not in vocab:\n",
        "                  orig.append(word.strip())\n",
        "                  word = self.assign_unk(word)\n",
        "                  prep.append(word)\n",
        "                  continue\n",
        "              else:\n",
        "                  orig.append(word.strip())\n",
        "                  prep.append(word.strip())\n",
        "\n",
        "      assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
        "      assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
        "\n",
        "      return orig, prep\n",
        "\n",
        "\n",
        "  def assign_unk(self, tok):\n",
        "    #Assign unk tags\n",
        "      if any(char.isdigit() for char in tok):\n",
        "          return \"--unk_digit--\"\n",
        "      elif any(char in self.punct for char in tok):\n",
        "          return \"--unk_punct--\"\n",
        "      elif any(char.isupper() for char in tok):\n",
        "          return \"--unk_upper--\"\n",
        "      elif any(tok.endswith(suffix) for suffix in self.noun_suffix):\n",
        "          return \"--unk_noun--\"\n",
        "      elif any(tok.endswith(suffix) for suffix in self.verb_suffix):\n",
        "          return \"--unk_verb--\"\n",
        "      elif any(tok.endswith(suffix) for suffix in self.adj_suffix):\n",
        "          return \"--unk_adj--\"\n",
        "      elif any(tok.endswith(suffix) for suffix in self.adv_suffix):\n",
        "          return \"--unk_adv--\"\n",
        "      return \"--unk--\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def create_dictionaries(self, training_corpus, vocab):\n",
        "      '''\n",
        "      Input: \n",
        "          prep: a preprocessed version of 'y'. A list with the 'word' component of the tuples.\n",
        "          training_corpus: a corpus composed of a list of tuples where each tuple consists of (word, POS)\n",
        "          vocab: a dictionary where keys are words in vocabulary and value is an index\n",
        "          \n",
        "      Output: \n",
        "          emission_counts: a dictionary where the keys are (tag,word) tuples and the value is the count\n",
        "          transition_counts: a dictionary where the keys are (prev_tag,curr_tag) tuples and the value is the count\n",
        "          tag_counts: a dictionary where the keys are tags and the value is the count\n",
        "      '''\n",
        "      #function to create dictionaries for counts of emissions, transitions, and tags\n",
        "      emission_counts = defaultdict(int)\n",
        "      transition_counts = defaultdict(int)\n",
        "      tag_counts = defaultdict(int)\n",
        "      \n",
        "      prev_tag = '--s--' \n",
        "\n",
        "      i = 0 \n",
        "\n",
        "      for word_tag in training_corpus:\n",
        "\n",
        "          i += 1\n",
        "\n",
        "          if i % 50000 == 0:\n",
        "              print(f\"word count = {i}\")\n",
        "          word,tag = self.get_word_tag(word_tag,vocab)\n",
        "          transition_counts[(prev_tag,tag)] += 1\n",
        "          emission_counts[(tag,word)] += 1\n",
        "          tag_counts[tag] += 1\n",
        "          prev_tag = tag\n",
        "          \n",
        "      return emission_counts, transition_counts, tag_counts\n",
        "\n",
        "\n",
        "  def predict_pos(self, prep, y, emission_counts, vocab, states):\n",
        "      '''\n",
        "      Input: \n",
        "          prep: a preprocessed version of 'y'. A list with the 'word' component of the tuples.\n",
        "          y: a corpus composed of a list of tuples where each tuple consists of (word, POS)\n",
        "          emission_counts: a dictionary where the keys are (tag,word) tuples and the value is the count\n",
        "          vocab: a dictionary where keys are words in vocabulary and value is an index\n",
        "          states: a sorted list of all possible tags for this assignment\n",
        "      Output: \n",
        "          accuracy: Number of times you classified a word correctly\n",
        "      '''\n",
        "      \n",
        "      # Initialize the number of correct predictions to zero\n",
        "      correct_pred=0\n",
        "      \n",
        "      # Get the (tag, word) tuples, stored as a set\n",
        "      y_tup=set(emission_counts.keys())\n",
        "      # Get the number of (word, POS) tuples in the corpus 'y'\n",
        "      number=len(y)\n",
        "\n",
        "\n",
        "          # Split the (word, POS) string into a list of two items\n",
        "      for w, y_tup in zip(prep,y):\n",
        "            l=y_tup.split()\n",
        "          \n",
        "          # Verify that y_tup contain both word and POS\n",
        "            if(len(l)==2):\n",
        "              # Set the true POS label for this word\n",
        "              true=l[1]\n",
        "\n",
        "              # If the y_tup didn't contain word and POS, go to next word\n",
        "            else:\n",
        "              pass\n",
        "          # If the word is in the vocabulary...\n",
        "            final_ct=0\n",
        "            final_pos=''\n",
        "            if w in vocab:\n",
        "              for pos in states:\n",
        "                k=(pos,w)\n",
        "  \n",
        "                  # define the key as the tuple containing the POS and word\n",
        "                  # check if the (pos, word) key exists in the emission_counts dictionary\n",
        "                if k in emission_counts.keys():\n",
        "\n",
        "                  count=emission_counts[k]\n",
        "\n",
        "                  # get the emission count of the (pos,word) tuple \n",
        "\n",
        "                      # keep track of the POS with the largest count\n",
        "                  if count>final_ct:\n",
        "                    final_ct=count\n",
        "                          # update the final count (largest count)\n",
        "                    final_pos=pos\n",
        "                          # update the final POS\n",
        "\n",
        "              # If the final POS (with the largest count) matches the true POS:\n",
        "            if final_pos== true:\n",
        "              correct_pred+=1   \n",
        "                  # Update the number of correct predictions\n",
        "\n",
        "              \n",
        "      ### END CODE HERE ###\n",
        "      accuracy = correct_pred/ number\n",
        "      \n",
        "      return accuracy\n"
      ],
      "metadata": {
        "id": "8ywObeFzjtGa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj= bruteforce(training=\"WSJ-2_21.pos\", voc= \"hmm_vocab.txt\", test_corpus=\"WSJ-24.pos\", test=\"test.words.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JKrU18W-lxON",
        "outputId": "49ff5d87-8284-449a-8229-06e6d327b9ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word count = 50000\n",
            "word count = 100000\n",
            "word count = 150000\n",
            "word count = 200000\n",
            "word count = 250000\n",
            "word count = 300000\n",
            "word count = 350000\n",
            "word count = 400000\n",
            "word count = 450000\n",
            "word count = 500000\n",
            "word count = 550000\n",
            "word count = 600000\n",
            "word count = 650000\n",
            "word count = 700000\n",
            "word count = 750000\n",
            "word count = 800000\n",
            "word count = 850000\n",
            "word count = 900000\n",
            "word count = 950000\n",
            "Accuracy of prediction using the brute force method is 88.885640 %\n"
          ]
        }
      ]
    }
  ]
}